"""
Data loading and preprocessing module for smart contract vulnerability detection.
Handles loading Solidity contracts and labels from the dataset.
"""

import os
import pandas as pd
import json
import sys
from typing import List, Tuple, Dict, Optional
import logging

# Try to import SmartBugs loader
try:
    from smartbugs_loader import SmartBugsLoader
    SMARTBUGS_AVAILABLE = True
except ImportError:
    SMARTBUGS_AVAILABLE = False

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class ContractDataLoader:
    """Loads and preprocesses smart contract data from the dataset."""
    
    def __init__(self, data_dir: str = "data", smartbugs_dir: Optional[str] = None):
        """
        Initialize the data loader.
        
        Args:
            data_dir: Directory containing the dataset
            smartbugs_dir: Optional directory containing SmartBugs results for real labels
        """
        self.data_dir = data_dir
        self.smartbugs_dir = smartbugs_dir
        self.contracts = []
        self.labels = []
        self.contract_ids = []  # Store contract IDs for label matching
        
        # Initialize SmartBugs loader if available
        self.smartbugs_loader = None
        if SMARTBUGS_AVAILABLE and smartbugs_dir and os.path.exists(smartbugs_dir):
            self.smartbugs_loader = SmartBugsLoader(smartbugs_dir)
            logger.info(f"SmartBugs loader initialized with directory: {smartbugs_dir}")
        elif smartbugs_dir:
            logger.warning(f"SmartBugs directory specified but not found: {smartbugs_dir}")
        
    def load_dataset(self, max_contracts: int = 10000) -> Tuple[List[str], List[int]]:
        """
        Load smart contracts and their vulnerability labels.
        
        Args:
            max_contracts: Maximum number of contracts to load (default 10000)
            
        Returns:
            Tuple of (contracts, labels) where contracts are Solidity code strings
            and labels are binary (1=vulnerable, 0=safe)
        """
        logger.info(f"Loading dataset from {self.data_dir}")
        
        contracts = []
        labels = []
        
        # Check if dataset directory exists
        if not os.path.exists(self.data_dir):
            logger.warning(f"Dataset directory {self.data_dir} not found. Creating sample structure.")
            return self._create_sample_data(max_contracts)
        
        # Try to load from CSV if available (common format for this dataset)
        csv_path = os.path.join(self.data_dir, "contracts.csv")
        if os.path.exists(csv_path):
            return self._load_from_csv(csv_path, max_contracts)
        
        # Try to load from JSON
        json_path = os.path.join(self.data_dir, "contracts.json")
        if os.path.exists(json_path):
            return self._load_from_json(json_path, max_contracts)
        
        # Try to load from directory structure (contracts/ and labels/)
        contracts_dir = os.path.join(self.data_dir, "contracts")
        labels_file = os.path.join(self.data_dir, "labels.csv")
        
        if os.path.exists(contracts_dir) and os.path.exists(labels_file):
            return self._load_from_directory(contracts_dir, labels_file, max_contracts)
        
        # Try to load from Ethereum smart contract dataset structure
        ethereum_dataset_path = os.path.join(self.data_dir, "Ethereum_smart_contract_datast", "contract_dataset_ethereum")
        if os.path.exists(ethereum_dataset_path):
            return self._load_from_ethereum_dataset(ethereum_dataset_path, max_contracts)
        
        # If no dataset found, create sample data for development
        logger.warning("No dataset found. Creating sample data structure.")
        return self._create_sample_data(max_contracts)
    
    def _load_from_csv(self, csv_path: str, max_contracts: int) -> Tuple[List[str], List[int]]:
        """Load data from CSV file."""
        df = pd.read_csv(csv_path, nrows=max_contracts)
        
        # Assume columns: 'code' or 'source_code' for contract, 'label' or 'vulnerable' for label
        code_col = None
        label_col = None
        
        for col in df.columns:
            if 'code' in col.lower() or 'source' in col.lower():
                code_col = col
            if 'label' in col.lower() or 'vulnerable' in col.lower() or 'vuln' in col.lower():
                label_col = col
        
        if code_col is None or label_col is None:
            raise ValueError(f"Could not find code or label columns in CSV. Columns: {df.columns.tolist()}")
        
        contracts = df[code_col].astype(str).tolist()
        labels = df[label_col].astype(int).tolist()
        
        logger.info(f"Loaded {len(contracts)} contracts from CSV")
        return contracts, labels
    
    def _load_from_json(self, json_path: str, max_contracts: int) -> Tuple[List[str], List[int]]:
        """Load data from JSON file."""
        with open(json_path, 'r') as f:
            data = json.load(f)
        
        contracts = []
        labels = []
        
        for item in data[:max_contracts]:
            if 'code' in item or 'source_code' in item:
                code = item.get('code') or item.get('source_code')
                label = item.get('label', item.get('vulnerable', 0))
                contracts.append(str(code))
                labels.append(int(label))
        
        logger.info(f"Loaded {len(contracts)} contracts from JSON")
        return contracts, labels
    
    def _load_from_directory(self, contracts_dir: str, labels_file: str, max_contracts: int) -> Tuple[List[str], List[int]]:
        """Load contracts from directory and labels from CSV."""
        labels_df = pd.read_csv(labels_file)
        contracts = []
        labels = []
        
        contract_files = [f for f in os.listdir(contracts_dir) if f.endswith('.sol')][:max_contracts]
        
        for contract_file in contract_files:
            contract_path = os.path.join(contracts_dir, contract_file)
            with open(contract_path, 'r', encoding='utf-8', errors='ignore') as f:
                code = f.read()
                contracts.append(code)
            
            # Try to find corresponding label
            contract_id = contract_file.replace('.sol', '')
            label_row = labels_df[labels_df['contract'] == contract_id] if 'contract' in labels_df.columns else None
            
            if label_row is not None and len(label_row) > 0:
                label = int(label_row.iloc[0]['label'] if 'label' in label_row.columns else label_row.iloc[0]['vulnerable'])
            else:
                label = 0  # Default to safe if label not found
            
            labels.append(label)
        
        logger.info(f"Loaded {len(contracts)} contracts from directory")
        return contracts, labels
    
    def _load_from_ethereum_dataset(self, dataset_path: str, max_contracts: int) -> Tuple[List[str], List[int]]:
        """
        Load contracts from Ethereum smart contract dataset structure.
        Dataset structure: contract_dataset_ethereum/contract1/, contract2/, etc.
        Each contract folder contains .sol files.
        """
        print(f"[DATA LOADER] Loading from Ethereum dataset at {dataset_path}", flush=True)
        logger.info(f"Loading from Ethereum dataset at {dataset_path}")
        sys.stdout.flush()
        
        contracts = []
        labels = []
        contract_ids = []  # Store contract IDs for label matching
        
        # Get all contract directories
        print("[DATA LOADER] Scanning contract directories...", flush=True)
        contract_dirs = [d for d in os.listdir(dataset_path) 
                       if os.path.isdir(os.path.join(dataset_path, d)) and d.startswith('contract')]
        contract_dirs.sort()
        
        print(f"[DATA LOADER] Found {len(contract_dirs)} contract directories", flush=True)
        print(f"[DATA LOADER] Loading up to {max_contracts} contracts...", flush=True)
        logger.info(f"Found {len(contract_dirs)} contract directories")
        logger.info(f"Loading up to {max_contracts} contracts...")
        sys.stdout.flush()
        
        # Load .sol files from all contract directories
        total_loaded = 0
        for idx, contract_dir in enumerate(contract_dirs):
            if len(contracts) >= max_contracts:
                break
            
            # Progress update every 5 directories
            if idx % 5 == 0:
                logger.info(f"Processing directory {idx+1}/{len(contract_dirs)}: {contract_dir} (loaded {len(contracts)}/{max_contracts} contracts)")
                sys.stdout.flush()  # Ensure immediate output
                
            contract_dir_path = os.path.join(dataset_path, contract_dir)
            sol_files = [f for f in os.listdir(contract_dir_path) if f.endswith('.sol')]
            
            for sol_file in sol_files:
                if len(contracts) >= max_contracts:
                    break
                    
                sol_path = os.path.join(contract_dir_path, sol_file)
                try:
                    with open(sol_path, 'r', encoding='utf-8', errors='ignore') as f:
                        code = f.read()
                        if len(code.strip()) > 0:  # Skip empty files
                            contracts.append(code)
                            
                            # Generate contract ID matching the format from label generator
                            # Format: contract_dir_filename (e.g., "contract25_24082")
                            contract_id = f"{contract_dir}_{sol_file.replace('.sol', '')}"
                            contract_ids.append(contract_id)
                            
                            # Since this dataset doesn't have labels, we'll mark all as safe (0)
                            # In a real scenario, you would need a separate labels file
                            labels.append(0)
                            total_loaded += 1
                            
                            # Progress update every 500 contracts
                            if total_loaded % 500 == 0:
                                logger.info(f"  Loaded {total_loaded}/{max_contracts} contracts...")
                                sys.stdout.flush()  # Ensure immediate output
                except Exception as e:
                    logger.debug(f"Error reading {sol_path}: {e}")
                    continue
        
        # Store contract IDs for later label matching
        self.contract_ids = contract_ids
        
        logger.info(f"Loaded {len(contracts)} contracts from Ethereum dataset")
        
        # Try to load real labels from JSON file or SmartBugs if available
        labels_json_path = os.path.join(self.data_dir, "labels_slither.json")
        if os.path.exists(labels_json_path):
            logger.info(f"Found labels file: {labels_json_path}")
            try:
                with open(labels_json_path, 'r') as f:
                    labels_dict = json.load(f)
                
                # Match contracts to labels using contract_ids
                matched_labels = []
                matched_count = 0
                for contract_id in self.contract_ids:
                    if contract_id in labels_dict:
                        matched_labels.append(labels_dict[contract_id])
                        matched_count += 1
                    else:
                        # If no match, default to safe
                        matched_labels.append(0)
                
                if matched_count > 0:
                    labels = matched_labels
                    vulnerable_count = sum(labels)
                    logger.info(f"Successfully loaded {matched_count} labels from JSON file")
                    logger.info(f"  - Vulnerable: {vulnerable_count} ({100*vulnerable_count/len(labels):.1f}%)")
                    logger.info(f"  - Safe: {len(labels)-vulnerable_count} ({100*(len(labels)-vulnerable_count)/len(labels):.1f}%)")
                else:
                    logger.warning("No matching labels found in JSON file. Using synthetic labels.")
                    labels = self._create_synthetic_labels(contracts)
            except Exception as e:
                logger.warning(f"Failed to load labels from JSON: {e}. Using synthetic labels.")
                labels = self._create_synthetic_labels(contracts)
        elif self.smartbugs_loader and all(label == 0 for label in labels):
            logger.info("Attempting to load real labels from SmartBugs...")
            try:
                smartbugs_labels = self.smartbugs_loader.load_labels()
                if smartbugs_labels:
                    labels = self.smartbugs_loader.match_contracts_to_labels(
                        contracts, self.contract_ids, smartbugs_labels
                    )
                    logger.info("Successfully loaded real labels from SmartBugs")
                else:
                    logger.warning("No SmartBugs labels found. Using synthetic labels.")
                    labels = self._create_synthetic_labels(contracts)
            except Exception as e:
                logger.warning(f"Failed to load SmartBugs labels: {e}. Using synthetic labels.")
                labels = self._create_synthetic_labels(contracts)
        elif all(label == 0 for label in labels):
            # If no labels found and no SmartBugs, create synthetic labels
            logger.warning("No labels found. Creating synthetic labels (20% vulnerable) for demonstration.")
            logger.warning("For real vulnerability detection, use a dataset with actual vulnerability labels.")
            labels = self._create_synthetic_labels(contracts)
        
        return contracts, labels
    
    def _create_synthetic_labels(self, contracts: List[str]) -> List[int]:
        """Create synthetic labels for demonstration."""
        import random
        random.seed(42)  # For reproducibility
        num_vulnerable = int(len(contracts) * 0.2)
        vulnerable_indices = random.sample(range(len(contracts)), num_vulnerable)
        
        labels = [1 if i in vulnerable_indices else 0 for i in range(len(contracts))]
        logger.info(f"Created synthetic labels: {sum(labels)} vulnerable, {len(labels)-sum(labels)} safe")
        return labels
    
    def _create_sample_data(self, max_contracts: int) -> Tuple[List[str], List[int]]:
        """
        Create sample Solidity contracts for testing when dataset is not available.
        This allows the code to run even without the actual dataset.
        """
        logger.info("Creating sample data for development/testing")
        
        # Sample vulnerable contract (reentrancy vulnerability)
        vulnerable_contract = """
        pragma solidity ^0.8.0;
        
        contract VulnerableBank {
            mapping(address => uint) public balances;
            
            function withdraw() public {
                uint amount = balances[msg.sender];
                (bool success, ) = msg.sender.call{value: amount}("");
                require(success, "Transfer failed");
                balances[msg.sender] = 0;
            }
            
            function deposit() public payable {
                balances[msg.sender] += msg.value;
            }
        }
        """
        
        # Sample safe contract
        safe_contract = """
        pragma solidity ^0.8.0;
        
        contract SafeBank {
            mapping(address => uint) public balances;
            bool private locked;
            
            modifier noReentrant() {
                require(!locked, "ReentrancyGuard: reentrant call");
                locked = true;
                _;
                locked = false;
            }
            
            function withdraw() public noReentrant {
                uint amount = balances[msg.sender];
                balances[msg.sender] = 0;
                (bool success, ) = msg.sender.call{value: amount}("");
                require(success, "Transfer failed");
            }
            
            function deposit() public payable {
                balances[msg.sender] += msg.value;
            }
        }
        """
        
        contracts = []
        labels = []
        
        # Generate mix of vulnerable and safe contracts
        for i in range(max_contracts):
            if i % 5 == 0:  # 20% vulnerable
                contracts.append(vulnerable_contract)
                labels.append(1)
            else:
                contracts.append(safe_contract)
                labels.append(0)
        
        logger.info(f"Created {len(contracts)} sample contracts ({sum(labels)} vulnerable, {len(labels)-sum(labels)} safe)")
        return contracts, labels
    
    def get_data_split(self, contracts: List[str], labels: List[int], 
                      test_size: float = 0.2, random_state: int = 42) -> Tuple:
        """
        Split data into train and test sets.
        
        Args:
            contracts: List of contract code strings
            labels: List of binary labels
            test_size: Proportion of test set
            random_state: Random seed
            
        Returns:
            Tuple of (X_train, X_test, y_train, y_test)
        """
        from sklearn.model_selection import train_test_split
        
        X_train, X_test, y_train, y_test = train_test_split(
            contracts, labels, test_size=test_size, random_state=random_state, stratify=labels
        )
        
        logger.info(f"Split data: Train={len(X_train)}, Test={len(X_test)}")
        logger.info(f"Train labels: {sum(y_train)} vulnerable, {len(y_train)-sum(y_train)} safe")
        logger.info(f"Test labels: {sum(y_test)} vulnerable, {len(y_test)-sum(y_test)} safe")
        
        return X_train, X_test, y_train, y_test
    
    def load_dataset_with_real_labels(
        self, 
        max_contracts: int = 10000,
        smartbugs_dir: Optional[str] = None
    ) -> Tuple[List[str], List[int]]:
        """
        Load dataset with real labels from SmartBugs.
        
        Args:
            max_contracts: Maximum number of contracts to load
            smartbugs_dir: Directory containing SmartBugs results (overrides init)
            
        Returns:
            Tuple of (contracts, labels) with real vulnerability labels
        """
        # Load contracts (using existing method)
        contracts, _ = self.load_dataset(max_contracts)
        
        # Load SmartBugs labels
        if smartbugs_dir:
            # Create temporary loader
            if SMARTBUGS_AVAILABLE:
                temp_loader = SmartBugsLoader(smartbugs_dir)
                smartbugs_labels = temp_loader.load_labels()
            else:
                smartbugs_labels = {}
        elif self.smartbugs_loader:
            smartbugs_labels = self.smartbugs_loader.load_labels()
        else:
            smartbugs_labels = {}
        
        # Match contracts to labels
        if smartbugs_labels:
            # Generate contract IDs
            contract_ids = [f"contract_{i}" for i in range(len(contracts))]
            
            if smartbugs_dir and SMARTBUGS_AVAILABLE:
                temp_loader = SmartBugsLoader(smartbugs_dir)
                labels = temp_loader.match_contracts_to_labels(
                    contracts, contract_ids, smartbugs_labels
                )
            elif self.smartbugs_loader:
                labels = self.smartbugs_loader.match_contracts_to_labels(
                    contracts, contract_ids, smartbugs_labels
                )
            else:
                labels = [0] * len(contracts)
        else:
            logger.warning("No SmartBugs labels available. Using synthetic labels.")
            labels = self._create_synthetic_labels(contracts)
        
        return contracts, labels

