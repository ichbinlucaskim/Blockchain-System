"""
Main script for Smart Contract Vulnerability Detection using Machine Learning.
Orchestrates the complete pipeline: data loading, feature extraction, model training, and evaluation.
"""

import argparse
import os
import sys
import numpy as np
import pandas as pd
import logging
from datetime import datetime
import time

# Add src directory to path
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

from data_loader import ContractDataLoader
from feature_extractor import FeatureExtractor
from models import ModelTrainer

# Configure logging with immediate flush
import sys
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    stream=sys.stdout,
    force=True
)
# Ensure immediate output
for handler in logging.root.handlers:
    handler.flush()

logger = logging.getLogger(__name__)


def main():
    """Main execution function."""
    parser = argparse.ArgumentParser(
        description='Smart Contract Vulnerability Detection using Machine Learning'
    )
    parser.add_argument(
        '--data-dir', 
        type=str, 
        default='data',
        help='Directory containing the dataset (default: data)'
    )
    parser.add_argument(
        '--max-contracts',
        type=int,
        default=10000,
        help='Maximum number of contracts to process (default: 10000)'
    )
    parser.add_argument(
        '--models-dir',
        type=str,
        default='models',
        help='Directory to save trained models (default: models)'
    )
    parser.add_argument(
        '--results-dir',
        type=str,
        default='results',
        help='Directory to save results (default: results)'
    )
    parser.add_argument(
        '--cv-folds',
        type=int,
        default=5,
        help='Number of cross-validation folds (default: 5)'
    )
    parser.add_argument(
        '--skip-training',
        action='store_true',
        help='Skip training and only evaluate existing models'
    )
    parser.add_argument(
        '--smartbugs-dir',
        type=str,
        default=None,
        help='Directory containing SmartBugs results for real vulnerability labels (optional)'
    )
    parser.add_argument(
        '--no-slither',
        action='store_true',
        help='Disable Slither feature extraction (much faster, uses basic features only)'
    )
    
    args = parser.parse_args()
    
    # Create necessary directories
    os.makedirs(args.results_dir, exist_ok=True)
    os.makedirs(args.models_dir, exist_ok=True)
    
    # Start timing
    pipeline_start_time = time.time()
    
    logger.info("="*60)
    logger.info("Smart Contract Vulnerability Detection")
    logger.info("="*60)
    logger.info(f"Data directory: {args.data_dir}")
    logger.info(f"Max contracts: {args.max_contracts}")
    logger.info(f"CV folds: {args.cv_folds}")
    logger.info("="*60)
    sys.stdout.flush()  # Ensure immediate output
    
    # Step 1: Load data
    logger.info("\n" + "="*60)
    logger.info("[Step 1/5] Loading dataset...")
    logger.info("="*60)
    data_loader = ContractDataLoader(data_dir=args.data_dir, smartbugs_dir=args.smartbugs_dir)
    
    # Try to load with real labels first, fallback to synthetic if not available
    try:
        if args.smartbugs_dir:
            logger.info("Attempting to load with real labels from SmartBugs...")
            contracts, labels = data_loader.load_dataset_with_real_labels(
                max_contracts=args.max_contracts,
                smartbugs_dir=args.smartbugs_dir
            )
            logger.info("✓ Using real labels from SmartBugs")
        else:
            logger.info("Loading dataset (will use synthetic labels if no SmartBugs directory provided)...")
            contracts, labels = data_loader.load_dataset(max_contracts=args.max_contracts)
            logger.info("✓ Using synthetic labels (no SmartBugs directory provided)")
    except Exception as e:
        logger.warning(f"Failed to load with real labels: {e}. Using default dataset loader.")
        contracts, labels = data_loader.load_dataset(max_contracts=args.max_contracts)
    
    step1_time = time.time() - pipeline_start_time
    logger.info(f"\n✓ Loaded {len(contracts)} contracts (took {step1_time:.1f} seconds)")
    logger.info(f"  - Vulnerable contracts: {sum(labels)} ({100*sum(labels)/len(labels):.2f}%)")
    logger.info(f"  - Safe contracts: {len(labels)-sum(labels)} ({100*(len(labels)-sum(labels))/len(labels):.2f}%)")
    sys.stdout.flush()
    
    # Step 2: Split data
    logger.info("\n" + "="*60)
    logger.info("[Step 2/5] Splitting data into train and test sets...")
    logger.info("="*60)
    X_train_raw, X_test_raw, y_train, y_test = data_loader.get_data_split(
        contracts, labels, test_size=0.2, random_state=42
    )
    step2_time = time.time() - pipeline_start_time - step1_time
    logger.info(f"✓ Split complete: Train={len(X_train_raw)}, Test={len(X_test_raw)} (took {step2_time:.1f} seconds)")
    sys.stdout.flush()
    
    # Step 3: Extract features
    step3_start_time = time.time()
    logger.info("\n" + "="*60)
    logger.info("[Step 3/5] Extracting features...")
    logger.info("="*60)
    logger.info("This is the most time-consuming step. Please be patient...")
    if args.no_slither:
        logger.info("NOTE: Slither is disabled. Using basic features only (faster execution).")
        logger.info("      If you want enhanced features, remove --no-slither flag (but it will be slower).")
    feature_extractor = FeatureExtractor(use_slither=not args.no_slither)
    
    logger.info(f"\nExtracting features from training set ({len(X_train_raw)} contracts)...")
    X_train = feature_extractor.extract_features(X_train_raw)
    
    logger.info(f"\nExtracting features from test set ({len(X_test_raw)} contracts)...")
    X_test = feature_extractor.extract_features(X_test_raw)
    
    step3_time = time.time() - step3_start_time
    logger.info(f"\n✓ Feature extraction complete (took {step3_time:.1f} seconds)")
    logger.info(f"Feature matrix shape: {X_train.shape}")
    logger.info(f"Number of features: {X_train.shape[1]}")
    sys.stdout.flush()
    
    # Save feature names
    feature_names = feature_extractor.get_feature_names()
    feature_names_df = pd.DataFrame({'feature_name': feature_names})
    feature_names_df.to_csv(
        os.path.join(args.results_dir, 'feature_names.csv'),
        index=False
    )
    logger.info(f"Saved feature names to {args.results_dir}/feature_names.csv")
    
    # Step 4: Train models
    logger.info("\n" + "="*60)
    logger.info("[Step 4/5] Training models...")
    logger.info("="*60)
    logger.info("This step involves hyperparameter tuning with cross-validation.")
    logger.info("It may take 10-30 minutes depending on data size and CV folds.")
    sys.stdout.flush()
    
    step4_start_time = time.time()
    if not args.skip_training:
        trainer = ModelTrainer(models_dir=args.models_dir)
        
        # Train Logistic Regression
        logger.info("\n" + "-"*60)
        logger.info("Training Logistic Regression (1/3)...")
        logger.info("-"*60)
        logger.info("Estimated time: 2-5 minutes")
        trainer.train_logistic_regression(X_train, y_train, cv_folds=args.cv_folds)
        trainer.save_model(trainer.models['logistic_regression'], 'logistic_regression')
        lr_time = time.time() - step4_start_time
        logger.info(f"✓ Logistic Regression training complete (took {lr_time:.1f} seconds)")
        sys.stdout.flush()
        
        # Train Random Forest
        rf_start_time = time.time()
        logger.info("\n" + "-"*60)
        logger.info("Training Random Forest (2/3)...")
        logger.info("-"*60)
        logger.info("Estimated time: 5-15 minutes")
        trainer.train_random_forest(X_train, y_train, cv_folds=args.cv_folds)
        trainer.save_model(trainer.models['random_forest'], 'random_forest')
        rf_time = time.time() - rf_start_time
        logger.info(f"✓ Random Forest training complete (took {rf_time:.1f} seconds)")
        sys.stdout.flush()
        
        # Train XGBoost
        xgb_start_time = time.time()
        try:
            logger.info("\n" + "-"*60)
            logger.info("Training XGBoost (3/3)...")
            logger.info("-"*60)
            logger.info("Estimated time: 5-15 minutes")
            trainer.train_xgboost(X_train, y_train, cv_folds=args.cv_folds)
            trainer.save_model(trainer.models['xgboost'], 'xgboost')
            xgb_time = time.time() - xgb_start_time
            logger.info(f"✓ XGBoost training complete (took {xgb_time:.1f} seconds)")
            sys.stdout.flush()
        except (ImportError, Exception) as e:
            logger.warning(f"XGBoost training skipped: {e}")
            sys.stdout.flush()
        
        step4_time = time.time() - step4_start_time
        logger.info(f"\n✓ All model training complete (total: {step4_time:.1f} seconds)")
        sys.stdout.flush()
    else:
        logger.info("Loading existing models...")
        trainer = ModelTrainer(models_dir=args.models_dir)
        trainer.models['logistic_regression'] = trainer.load_model('logistic_regression')
        trainer.models['random_forest'] = trainer.load_model('random_forest')
        try:
            trainer.models['xgboost'] = trainer.load_model('xgboost')
        except Exception as e:
            logger.warning(f"Could not load XGBoost model: {e}")
    
    # Step 5: Evaluate models
    logger.info("\n" + "="*60)
    logger.info("[Step 5/5] Evaluating models on test set...")
    logger.info("="*60)
    results_df = trainer.compare_models(X_test, y_test)
    
    # Save results
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    results_path = os.path.join(args.results_dir, f'results_{timestamp}.csv')
    results_df.to_csv(results_path)
    logger.info(f"\nSaved results to {results_path}")
    
    # Save detailed results with best parameters
    if hasattr(trainer, 'best_params') and trainer.best_params:
        best_params_df = pd.DataFrame(trainer.best_params).T
        best_params_path = os.path.join(args.results_dir, f'best_params_{timestamp}.csv')
        best_params_df.to_csv(best_params_path)
        logger.info(f"Saved best parameters to {best_params_path}")
    
    # Summary
    logger.info("\n" + "="*60)
    logger.info("SUMMARY")
    logger.info("="*60)
    logger.info(f"\nBest F1-score: {results_df['f1_score'].max():.4f}")
    logger.info(f"Best model: {results_df['f1_score'].idxmax()}")
    logger.info(f"\nLowest FPR: {results_df['false_positive_rate'].min():.4f}")
    logger.info(f"Model with lowest FPR: {results_df['false_positive_rate'].idxmin()}")
    
    # Check if XGBoost meets expected outcomes
    if 'xgboost' in results_df.index:
        xgb_f1 = results_df.loc['xgboost', 'f1_score']
        xgb_fpr = results_df.loc['xgboost', 'false_positive_rate']
        
        logger.info("\n" + "="*60)
        logger.info("XGBOOST PERFORMANCE vs EXPECTED OUTCOMES")
        logger.info("="*60)
        logger.info(f"Expected F1-score: >= 0.85")
        logger.info(f"Actual F1-score: {xgb_f1:.4f}")
        logger.info(f"Expected FPR: < 0.10")
        logger.info(f"Actual FPR: {xgb_fpr:.4f}")
        
        if xgb_f1 >= 0.85 and xgb_fpr < 0.10:
            logger.info("✓ XGBoost meets expected outcomes!")
        else:
            logger.info("⚠ XGBoost does not fully meet expected outcomes")
    
    total_time = time.time() - pipeline_start_time
    logger.info("\n" + "="*60)
    logger.info("Pipeline completed successfully!")
    logger.info(f"Total execution time: {total_time:.1f} seconds ({total_time/60:.1f} minutes)")
    logger.info("="*60)
    sys.stdout.flush()


if __name__ == "__main__":
    main()

