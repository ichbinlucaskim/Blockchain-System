## Team Members
- Lucas Kim

## Project Information

**Project Title:** Smart Contract Vulnerability Detection Using Machine Learning

**Dataset:** Smart-Contract-Dataset from GitHub (https://github.com/Messi-Q/Smart-Contract-Dataset)
- Contains 12,000+ real Ethereum smart contracts from Etherscan (2020-2025)
- Includes Solidity source code and labels for 8 vulnerability types
- Dataset size: 50 MB; 20% vulnerable
- Focus: Binary classification (vulnerable vs safe)

**External Resources:**
- Dataset: https://github.com/Messi-Q/Smart-Contract-Dataset
- SmartBugs: https://github.com/smartbugs/smartbugs (for real vulnerability labels)
- SWC Registry: https://github.com/SmartContractSecurity/SWC-registry
- Tools: slither-analyzer (required for enhanced features), py-solc-x (optional)
- Libraries: Scikit-learn, XGBoost

## Project Structure

```
code/
├── main.py                    # Main execution script
├── tune_hyperparameters.py    # Hyperparameter tuning script
├── test_pipeline.py           # Quick test script
├── generate_statistics.py     # Statistics and visualization generation
├── requirements.txt           # Python dependencies
├── README.md                  # This file
├── src/                       # Source code modules
│   ├── __init__.py
│   ├── data_loader.py         # Data loading and preprocessing
│   ├── feature_extractor.py   # Feature extraction (opcodes, AST, Slither)
│   ├── slither_extractor.py   # Slither-based static analysis features
│   ├── smartbugs_loader.py    # SmartBugs label loader
│   └── models.py              # Model training and evaluation
├── data/                      # Dataset directory (create and add data here)
├── models/                    # Saved trained models (created automatically)
└── results/                   # Evaluation results (created automatically)
```

## How to Run the Code

### 1. Install Dependencies

```bash
pip install -r requirements.txt
```

### 2. Prepare Dataset

Place your dataset in the `data/` directory. The code supports multiple formats:
- CSV file with columns for contract code and labels
- JSON file with contract objects
- Directory structure with `contracts/` folder and `labels.csv`

If no dataset is found, the code will generate sample data for testing.

### 3. Run the Pipeline

**Basic usage:**
```bash
python main.py
```

**With custom parameters:**
```bash
python main.py --data-dir data --max-contracts 2000 --cv-folds 5
```

**With SmartBugs labels (real vulnerability labels):**
```bash
python main.py --data-dir data --max-contracts 2000 --smartbugs-dir /path/to/smartbugs/results
```

**Command-line arguments:**
- `--data-dir`: Directory containing the dataset (default: `data`)
- `--max-contracts`: Maximum number of contracts to process (default: 10000)
- `--models-dir`: Directory to save trained models (default: `models`)
- `--results-dir`: Directory to save results (default: `results`)
- `--cv-folds`: Number of cross-validation folds (default: 5)
- `--skip-training`: Skip training and only evaluate existing models

### 4. Hyperparameter Tuning

For optimized performance, use the hyperparameter tuning script:

**Basic tuning:**
```bash
python tune_hyperparameters.py --max-contracts 2000
```

**With SmartBugs labels:**
```bash
python tune_hyperparameters.py --max-contracts 2000 --smartbugs-dir /path/to/smartbugs/results
```

**Tuning script arguments:**
- `--data-dir`: Directory containing the dataset (default: `data`)
- `--smartbugs-dir`: Directory containing SmartBugs results (optional)
- `--max-contracts`: Maximum number of contracts to use (default: 2000)
- `--cv-folds`: Number of cross-validation folds (default: 5)
- `--models-dir`: Directory to save tuned models (default: `models`)
- `--skip-tuning`: Skip tuning and only evaluate existing models

### 5. View Results

Results are saved in the `results/` directory:
- `results_YYYYMMDD_HHMMSS.csv`: Model comparison metrics
- `best_params_YYYYMMDD_HHMMSS.csv`: Best hyperparameters for each model
- `tuning_results_YYYYMMDD_HHMMSS.csv`: Hyperparameter tuning results
- `feature_names.csv`: List of extracted features
- `model_comparison.png`: Visualization of model performance
- `dataset_distribution.png`: Dataset class distribution

## Dependencies

```
python>=3.8
numpy>=1.21.0
pandas>=1.3.0
scikit-learn>=1.0.0
xgboost>=1.5.0
joblib>=1.0.0
slither-analyzer>=0.9.0
```

**Required for Slither features:**
- `slither-analyzer`: Static analysis framework for Solidity
- `solc`: Solidity compiler (install via `brew install solidity` on macOS)

**Optional:**
- `py-solc-x`: Python wrapper for Solidity compiler
- SmartBugs results: For real vulnerability labels (see SmartBugs section below)

## Features Extracted

The pipeline extracts the following features from Solidity contracts:

### Basic Features (71 features)
1. **Opcodes** (35 features): Frequency of opcodes like CALL, SSTORE, SLOAD, etc.
2. **AST Nodes** (21 features): Counts of AST node types (FunctionDefinition, ModifierDefinition, etc.)
3. **Control Flow** (5 features): Nesting depth, loop counts, external calls, etc.
4. **Code Metrics** (7 features): Lines, characters, functions, state variables, etc.

### Enhanced Features with Slither (39 additional features)
5. **Detector Features** (11 features): Reentrancy, unchecked transfer, tx-origin, etc.
6. **CFG Metrics** (5 features): Control flow graph nodes, edges, depth, branches
7. **Call Graph Metrics** (5 features): External calls, delegate calls, recursive calls
8. **Inheritance Metrics** (4 features): Inheritance depth, multiple inheritance
9. **Function Features** (8 features): Function counts, visibility, payable, view, pure
10. **Variable Features** (6 features): Variable counts, visibility, initialization status

**Total: 110 features per contract** (71 basic + 39 Slither)

*Note: If Slither is not available or fails, the pipeline falls back to basic features only.*

## Models

Three classification models are trained and compared:

1. **Logistic Regression**: Baseline model with L1/L2 regularization
2. **Random Forest**: Ensemble of decision trees
3. **XGBoost**: Gradient boosting (expected best performer)

All models use:
- 5-fold cross-validation for hyperparameter tuning
- Grid search for optimal parameters (via `tune_hyperparameters.py`)
- Class weighting to handle imbalanced data
- F1-score as the primary evaluation metric

**Hyperparameter Tuning:**
- Use `tune_hyperparameters.py` for optimized model performance
- Automatically searches for best parameters to achieve F1 ≥ 0.85 and FPR < 0.10
- Saves tuned models for future use

## Expected Outcomes

Based on the proposal and improvements:
- **Target F1-score**: ≥ 85% (with real labels and Slither features)
- **Target False Positive Rate**: < 10%
- XGBoost should outperform baselines by 5-10 percentage points

**Performance Improvement:**
- **Current (synthetic labels)**: F1 ~0.30, FPR 0.40-0.56
- **Target (real labels + Slither)**: F1 ≥ 0.85, FPR < 0.10
- **Improvement factors**:
  1. Real vulnerability labels from SmartBugs
  2. Enhanced features from Slither static analysis
  3. Optimized hyperparameters via grid search

## SmartBugs Integration

To use real vulnerability labels from SmartBugs:

1. **Install SmartBugs** (optional, for generating labels):
   ```bash
   git clone https://github.com/smartbugs/smartbugs.git
   cd smartbugs
   docker-compose build
   ```

2. **Run SmartBugs** on your contracts (or use existing results)

3. **Use SmartBugs labels** in the pipeline:
   ```bash
   python main.py --smartbugs-dir /path/to/smartbugs/results
   ```

The pipeline will automatically:
- Load SmartBugs JSON results
- Match contracts to vulnerability labels
- Use real labels instead of synthetic ones

If SmartBugs directory is not provided, the pipeline uses synthetic labels (20% vulnerable) for demonstration.

## Recent Improvements (Week 12-13)

The following improvements have been implemented:

1. **Slither Integration**: Added 39 static analysis features via Slither
2. **SmartBugs Support**: Real vulnerability label loading from SmartBugs results
3. **Hyperparameter Tuning**: Automated tuning script for optimal performance
4. **Enhanced Features**: Total features increased from 71 to 110

See `IMPROVEMENTS_SUMMARY.md` for detailed information.

## Acknowledgments

- Dataset: Messi-Q, "Smart-contract-dataset," https://github.com/Messi-Q/Smart-Contract-Dataset, 2025
- SmartBugs: https://github.com/smartbugs/smartbugs - Vulnerability detection framework
- SWC Registry: https://github.com/SmartContractSecurity/SWC-registry - Smart Contract Weakness Classification
- Slither: https://github.com/crytic/slither - Static analysis framework
- All code implemented from scratch (no code cloning)

## Contact

For questions about this project, please contact:
- Lucas Kim: lkim60@lion.lmu.edu

---

**Note:** Remember that academic integrity is essential. All external code, datasets, and resources must be properly cited and acknowledged.